import csv
import random
import os
import nltk
import re

def getNbTopics(key,feedback,nb_topics_min):
		if(key in feedback.iterkeys()):
			nb_topics_trouve = len(feedback[key])
		else: 
			return 2
		no_subtopic = 0
		if nb_topics_trouve > 0:
			subtopic_ids = [key in feedback.iterkeys()]
			for subtopic in subtopic_ids:
				if(subtopic[-2] != '.'):
					no_subtopic = subtopic[-2] + subtopic[-1]
				else:
					no_subtopic = subtopic[-1]
				if(int(no_subtopic) > nb_topics_min):
					nb_topics_min = no_subtopic
		return nb_topics_min
	
def get_rand_doc_from_list(domain_name = 'ebola'):
	path = os.path.dirname(os.path.abspath(__file__))
	with open(path + '/list_' + domain_name + '.csv', 'rb') as csvfile:
		list_reader = csv.reader(csvfile, delimiter=' ', quotechar='|')
		list_docs = list(list_reader)
		nb_docs = len(list_docs)
		doc_nb = random.randint(1,nb_docs)
		print nb_docs,doc_nb
		for i,row in enumerate(list_docs):
			if(i==doc_nb):
				return row[0]

def NErecognition(content,listNE = ['GPE','ORGANIZATION','PERSON'],return_type = 'entities'):
	item = content
	entityList = []
	tokenized = nltk.word_tokenize(item)
	tagged = nltk.pos_tag(tokenized)
	namedEnt = nltk.ne_chunk(tagged)
	if(return_type == 'type_entities'):
		return namedEnt
	for i in range(len(namedEnt)):
		if  not isinstance(namedEnt[i][0], basestring):
			#print 'print named entity : ' + str(namedEnt[i])
			entity = ""
			for j in range(len(namedEnt[i])):
				if j==0:
					entity = namedEnt[i][j][0]
				else:
					entity = entity + " " + namedEnt[i][j][0]
			reNE = ""
			for NE in range(len(listNE)):
				if(NE==0):
					reNE = listNE[NE]
				else:
					reNE = reNE + "|" + listNE[NE]

			m = re.search('\(('+ reNE +')(\s)',str(namedEnt[i]))
			if m:
				typeEntity =  m.group(1)
				entityList.append((entity,typeEntity))
	return [elem[0] for elem in entityList]

if __name__ == '__main__':
	print get_rand_doc_from_list()
	print NErecognition('Deep Web Description Illegal Activity and SEO',return_type = 'type_entities')
