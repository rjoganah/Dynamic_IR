## CubeTest Implementation For TREC Dynamic Domain Track Evaluation
## For Linux Unix Platform

## Copyright by InfoSense Group, Georgetown University
## Version: lgc
## Date: 12/03/2014
----------------------------------------------------

To run CubeTest, you can:

	perl sampleEvalRunCT.pl
	
	# using the sample input(./test/runs/)

	# a result directory will be created
	
OR
	
	perl evalRunCT.pl qrel inputDir cutoff target\n
	
	# providing with specific parameters
	
	# qrel is the ground truth file
	# inputDir is the directory for returned document rank lists
	# cutoff is a reporting depth for results
	# target is the new directory to be created for storing evaluation results 

------------------------------------------------------

The main evaluation code is in cubeTest.pl  

For each returned ranklist, evalRunCT.pl will call cubeTest.pl to evaluate it in terms of each topic.

------------------------------------------------------

qrel(ground truth)'s format:

	topicID subtopicID docID relevanceJudgment subtopicWeight

system run's format:

	topicID q0 docID rank score runID docLength

------------------------------------------------------

This version(lgc) of CubeTest adopted following computational choices:

l: Subtopic importance is generated by a decay function theta(k) = 1/log2(1+k) and normalized the range of [0~1]

g: Calculate time using Time(k) = SUM(j=1~k-1)[4.4 + ri*(0.018lj + 7.8)], where ri = 0.64 if dj is relevant, otherwise 0.39

c: Assume the task cube has a top cover and subtopic's gain will not increase if the height reaches 1

gamma = 0.5 (coefficient for adjusting CubeTest's degree of how much bias towards subtopic coverage)